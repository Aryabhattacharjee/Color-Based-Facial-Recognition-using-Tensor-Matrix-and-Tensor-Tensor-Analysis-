{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_range_string(range_string):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "    - range_string (str): A string containing numbers and ranges, e.g., \"1,3,5-7,9-11\"\n",
    "    \n",
    "    Returns:\n",
    "    - numbers (list of int): A list of numbers extracted from the range string.[1,3,5,6,7,9,10,11]\n",
    "    \"\"\"\n",
    "    numbers = []\n",
    "    \n",
    "    # Split the string by commas to handle each part\n",
    "    parts = range_string.split(',')\n",
    "    \n",
    "    for part in parts:\n",
    "        if '-' in part:\n",
    "            # If the part contains a hyphen, it's a range\n",
    "            start, end = part.split('-')\n",
    "            start, end = int(start), int(end)\n",
    "            numbers.extend(range(start, end + 1))  # Use range to generate the numbers in the range\n",
    "        else:\n",
    "            # If the part is a single number, just add it to the list\n",
    "            numbers.append(int(part))\n",
    "    \n",
    "    return numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 10.2.0\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "print('PIL',PIL.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.26.3\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print('numpy',numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def img_to_tensor(image_path):\n",
    "\n",
    "    # Args:\n",
    "    # - image_path (str): Path to the image file, e.g., 'home/data/pic.jpg'\n",
    "\n",
    "    # Returns:\n",
    "    # - image_tensor (torch.Tensor): The image as a tensor.\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')  # Ensure image is in RGB mode\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    image_tensor = transform(image)\n",
    "    return image_tensor\n",
    "\n",
    "def load_images_to_tensor_list(folder_path,persons_range,person_img_range):\n",
    "\n",
    "    persons_list=parse_range_string(persons_range)\n",
    "    person_img_list=parse_range_string(person_img_range)\n",
    "    \n",
    "    # Args:\n",
    "    # - folder_path (str): Path to the folder containing the images.\n",
    "    \n",
    "    # Returns:\n",
    "    # - tensor_list (list of list of torch.Tensor): A 50x14 list of image tensors.\n",
    "    \n",
    "    tensor_list = []\n",
    "\n",
    "    for i in persons_list:\n",
    "        row = []\n",
    "        for j in person_img_list:\n",
    "            image_name = f\"{i}-{j:02d}.jpg\"  # Format image name jpg or jpeg or png\n",
    "            image_path = os.path.join(folder_path, image_name)\n",
    "            if os.path.exists(image_path):\n",
    "                image_tensor = img_to_tensor(image_path)\n",
    "                row.append(image_tensor)\n",
    "            else:\n",
    "                print(f\"Image not found: {image_path}\")\n",
    "                break\n",
    "        tensor_list.append(row)\n",
    "    \n",
    "    return tensor_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "person_matrix is a p x n matrix where each row represent  a different person. and elements of that row is tensor form of different image of that person.\n",
    "each element of this matrix should be a  torch (3 x i_1 x i_2) tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def train(person_matrix,LS):\n",
    "\n",
    "    p=len(person_matrix)\n",
    "    n=len(person_matrix[0])\n",
    "    sample_img=person_matrix[0][0]\n",
    "    i_1=sample_img.size()[1]   # i_1\n",
    "    i_2=sample_img.size()[2]   # i_2   \n",
    "\n",
    "    # create a 3*i1*i2 tensor of zeros\n",
    "    meanAll=torch.zeros(3,i_1,i_2)     # in torch (3*i1*i2) is same as (i1*i2*3) i paper\n",
    "    for i in range(p):\n",
    "        for j in range(n):\n",
    "            meanAll=meanAll+person_matrix[i][j]\n",
    "    meanAll=meanAll/(p*n)\n",
    "\n",
    "    TensorCov=torch.zeros(3,i_2,i_2)\n",
    "    for i in range(p):\n",
    "        for j in range(n):\n",
    "            temp=person_matrix[i][j]-meanAll\n",
    "            TensorCov=TensorCov+torch.matmul(temp.mT, temp)\n",
    "    TensorCov=TensorCov/(p*n)\n",
    "\n",
    "\n",
    "    TenU,TenS,TenV_transpose=torch.linalg.svd(TensorCov, full_matrices=True) # here TenS is only the diagonal part\n",
    "\n",
    "\n",
    "    TenFeature=[]\n",
    "    for i in range(p):\n",
    "        TenFeature.append([])\n",
    "        for j in range(n):\n",
    "            temp=torch.matmul(person_matrix[i][j], TenU[:,:,:LS])\n",
    "            TenFeature[i].append(temp)\n",
    "\n",
    "    return TenFeature, TenU[:,:,:LS]  # we need to pass this two as 2nd and 3rd parameter accordingly in eval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(target_img_tensor,TenFeature, TenU_LS):\n",
    "    TenFeature_j=torch.matmul(target_img_tensor, TenU_LS)\n",
    "    p=len(TenFeature)\n",
    "    n=len(TenFeature[0])\n",
    "    eval=torch.zeros(p,n)\n",
    "    for i in range(p):\n",
    "        for j in range(n):\n",
    "            eval[i][j]=torch.norm(TenFeature[i][j]-TenFeature_j)\n",
    "    # find p of the min value in eval\n",
    "    min_val=eval.min()\n",
    "    for i in range(len(eval)):\n",
    "        for j in range(len(eval[0])):\n",
    "            if eval[i][j] == min_val:\n",
    "                return i+1\n",
    "# we assome person class start from zero. so if 5 defferent person is there then the person classes (p) will be 0,1,2,3,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created a 50x7 list of image tensors.\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the folder containing the images\n",
    "folder_path = \"/home/arya/my_python/my_torch/img\"\n",
    "\n",
    "# Load the images into a 50x14 list of tensors\n",
    "image_tensor_train= load_images_to_tensor_list(folder_path,\"1-50\",\"1,3,5,7,9,11,13\")\n",
    "\n",
    "# Check if the list was created successfully\n",
    "print(f\"Successfully created a {len(image_tensor_train)}x{len(image_tensor_train[0])} list of image tensors.\")\n",
    "\n",
    "a=train(image_tensor_train,LS=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 1, 1, 1, 1, 37], [2, 2, 2, 2, 2, 2, 37], [3, 3, 3, 3, 3, 3, 37], [4, 4, 4, 4, 4, 4, 37], [5, 5, 5, 5, 5, 5, 37], [6, 6, 6, 6, 19, 6, 37], [7, 7, 7, 7, 10, 7, 37], [8, 8, 8, 8, 8, 8, 37], [9, 9, 9, 9, 9, 9, 9], [10, 10, 10, 10, 10, 10, 10], [11, 11, 11, 11, 21, 11, 11], [12, 12, 12, 12, 25, 12, 12], [13, 13, 13, 13, 13, 13, 37], [14, 14, 14, 14, 13, 14, 37], [15, 15, 15, 15, 15, 15, 15], [16, 16, 16, 16, 16, 16, 16], [17, 17, 17, 17, 36, 17, 17], [18, 18, 18, 18, 18, 18, 20], [19, 19, 19, 19, 19, 19, 19], [20, 20, 20, 20, 18, 20, 20], [21, 21, 21, 21, 21, 21, 37], [22, 22, 22, 22, 8, 22, 37], [23, 23, 23, 23, 23, 23, 37], [24, 24, 24, 24, 24, 24, 37], [25, 25, 20, 25, 25, 25, 38], [26, 26, 26, 26, 26, 26, 38], [27, 27, 27, 27, 27, 27, 37], [28, 28, 11, 28, 28, 28, 37], [29, 29, 29, 29, 29, 29, 29], [30, 30, 30, 30, 30, 30, 30], [31, 31, 31, 31, 31, 31, 31], [32, 32, 32, 32, 32, 32, 32], [33, 33, 33, 33, 18, 33, 8], [34, 34, 34, 34, 34, 34, 37], [35, 35, 35, 35, 35, 35, 7], [36, 36, 36, 36, 36, 36, 37], [37, 37, 37, 37, 37, 37, 37], [38, 38, 38, 38, 38, 38, 37], [39, 39, 39, 39, 39, 39, 39], [40, 40, 40, 40, 9, 40, 40], [41, 41, 41, 41, 41, 41, 41], [42, 42, 42, 42, 42, 42, 42], [43, 43, 43, 43, 43, 43, 43], [44, 44, 44, 44, 44, 44, 8], [45, 45, 45, 45, 45, 45, 45], [46, 46, 46, 46, 46, 46, 37], [47, 47, 47, 47, 47, 47, 37], [48, 48, 48, 48, 48, 48, 37], [49, 49, 49, 49, 49, 49, 37], [50, 50, 50, 50, 1, 50, 37]]\n"
     ]
    }
   ],
   "source": [
    "test_person_tensor=load_images_to_tensor_list(folder_path,\"1-50\",\"2,4,6,8,10,12,14\")\n",
    "count=0\n",
    "for i in range(50):\n",
    "    for j in range (7):\n",
    "        test_person_tensor[i][j]=eval(test_person_tensor[i][j],a[0],a[1])\n",
    "print(test_person_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LS_accuracy_check(LS):\n",
    "    # Define the path to the folder containing the images\n",
    "    folder_path = \"/home/arya/my_python/my_torch/img\"\n",
    "\n",
    "    # Load the images into a 50x14 list of tensors\n",
    "    train_person_tensors= load_images_to_tensor_list(folder_path,\"1-50\",\"1,3,5,7,9,11,12,14\")\n",
    "    \n",
    "    a=train(train_person_tensors,LS)\n",
    "\n",
    "    test_person_tensor=load_images_to_tensor_list(folder_path,\"1-50\",\"2,4,6,8,10,13\")\n",
    "    count=0\n",
    "    for i in range(50):\n",
    "        for j in range (6):\n",
    "            if i+1==eval(test_person_tensor[i][j],a[0],a[1]):\n",
    "                count+=1\n",
    "    accuracy=count*100/(50*6)\n",
    "    print(f\"for ls={LS} accuracy on test set is {accuracy}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for ls=1 accuracy on test set is 89.66666666666667%\n",
      "for ls=2 accuracy on test set is 92.0%\n",
      "for ls=3 accuracy on test set is 93.0%\n",
      "for ls=4 accuracy on test set is 94.33333333333333%\n",
      "for ls=5 accuracy on test set is 92.66666666666667%\n",
      "for ls=6 accuracy on test set is 92.33333333333333%\n",
      "for ls=7 accuracy on test set is 92.0%\n",
      "for ls=8 accuracy on test set is 92.33333333333333%\n",
      "for ls=9 accuracy on test set is 92.66666666666667%\n",
      "for ls=10 accuracy on test set is 92.0%\n",
      "for ls=11 accuracy on test set is 91.33333333333333%\n",
      "for ls=12 accuracy on test set is 91.33333333333333%\n",
      "for ls=13 accuracy on test set is 91.33333333333333%\n",
      "for ls=14 accuracy on test set is 91.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "LS_accuracy_check(1)\n",
    "LS_accuracy_check(2)\n",
    "LS_accuracy_check(3)\n",
    "LS_accuracy_check(4) # till 4 it is good then start to get over fitted\n",
    "LS_accuracy_check(5)\n",
    "LS_accuracy_check(6)\n",
    "LS_accuracy_check(7)\n",
    "LS_accuracy_check(8)\n",
    "LS_accuracy_check(9)\n",
    "LS_accuracy_check(10)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
